{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "13cc4279e015afd27a75fe57b0b98b1a4c1fa549"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-d99a9c07c14c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilterwarnings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ignore'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from scipy.stats import skew\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor\n",
    "from sklearn.svm import SVR, LinearSVR\n",
    "from sklearn.linear_model import ElasticNet, SGDRegressor, BayesianRidge\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from xgboost import XGBRegressor\n",
    "train = pd.read_csv('./data/train.csv')\n",
    "test = pd.read_csv('./data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "4b65b02b1f81bf05c4eea18e71549f22ec8bb758"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "sns.boxplot(train.YearBuilt, train.SalePrice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "6b710f1c3011b1eb6a9a5a7efe336fcf2cc06abe"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.scatter(x=train.GrLivArea, y=train.SalePrice)\n",
    "plt.xlabel(\"GrLivArea\", fontsize=13)\n",
    "plt.ylabel(\"SalePrice\", fontsize=13)\n",
    "plt.ylim(0,800000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "941bef27b2dcd9c3abb41630d4318cfac64e88eb"
   },
   "outputs": [],
   "source": [
    "train.drop(train[(train[\"GrLivArea\"]>4000)&(train[\"SalePrice\"]<300000)].index,inplace=True)\n",
    "full=pd.concat([train,test], ignore_index=True)\n",
    "full.drop(['Id'],axis=1, inplace=True)\n",
    "full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "0ed5ef81fdcb124f6610e89862cad4307dffebdd"
   },
   "outputs": [],
   "source": [
    "aa = full.isnull().sum()\n",
    "aa[aa>0].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "cab06c21760457f02182e276c77f4760f07d5d14"
   },
   "outputs": [],
   "source": [
    "full.groupby(['Neighborhood'])[['LotFrontage']].agg(['mean','median','count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "6380dccfbb49b7e5f679c38203d638c5db0378cb"
   },
   "outputs": [],
   "source": [
    "full[\"LotAreaCut\"] = pd.qcut(full.LotArea,10)\n",
    "full.groupby(['LotAreaCut'])[['LotFrontage']].agg(['mean','median','count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "67fb797cc7b4463f804ead77107f597aa5146664"
   },
   "outputs": [],
   "source": [
    "# Since some combinations of LotArea and Neighborhood are not available, so we just LotAreaCut alone.\n",
    "full['LotFrontage']=full.groupby(['LotAreaCut'])['LotFrontage'].transform(lambda x: x.fillna(x.median()))\n",
    "\n",
    "cols=[\"MasVnrArea\", \"BsmtUnfSF\", \"TotalBsmtSF\", \"GarageCars\", \"BsmtFinSF2\", \"BsmtFinSF1\", \"GarageArea\"]\n",
    "for col in cols:\n",
    "    full[col].fillna(0, inplace=True)\n",
    "\n",
    "cols1 = [\"PoolQC\" , \"MiscFeature\", \"Alley\", \"Fence\", \"FireplaceQu\", \"GarageQual\", \"GarageCond\", \"GarageFinish\", \"GarageYrBlt\", \"GarageType\", \"BsmtExposure\", \"BsmtCond\", \"BsmtQual\", \"BsmtFinType2\", \"BsmtFinType1\", \"MasVnrType\"]\n",
    "for col in cols1:\n",
    "    full[col].fillna(\"None\", inplace=True)\n",
    "\n",
    "# fill in with mode\n",
    "cols2 = [\"MSZoning\", \"BsmtFullBath\", \"BsmtHalfBath\", \"Utilities\", \"Functional\", \"Electrical\", \"KitchenQual\", \"SaleType\",\"Exterior1st\", \"Exterior2nd\"]\n",
    "for col in cols2:\n",
    "    full[col].fillna(full[col].mode()[0], inplace=True)\n",
    "full.isnull().sum()[full.isnull().sum()>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_uuid": "878e5e09362afdf827a5144ab5145ca93365b838"
   },
   "outputs": [],
   "source": [
    "NumStr = [\"MSSubClass\",\"BsmtFullBath\",\"BsmtHalfBath\",\"HalfBath\",\"BedroomAbvGr\",\"KitchenAbvGr\",\"MoSold\",\"YrSold\",\"YearBuilt\",\"YearRemodAdd\",\"LowQualFinSF\",\"GarageYrBlt\"]\n",
    "for col in NumStr:\n",
    "    full[col]=full[col].astype(str)\n",
    "full.groupby(['MSSubClass'])[['SalePrice']].agg(['mean','median','count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_uuid": "512bce4d89c2989876e1ac872309d8a603b04073"
   },
   "outputs": [],
   "source": [
    "def map_values():\n",
    "    full[\"oMSSubClass\"] = full.MSSubClass.map({'180':1, \n",
    "                                        '30':2, '45':2, \n",
    "                                        '190':3, '50':3, '90':3, \n",
    "                                        '85':4, '40':4, '160':4, \n",
    "                                        '70':5, '20':5, '75':5, '80':5, '150':5,\n",
    "                                        '120': 6, '60':6})\n",
    "    \n",
    "    full[\"oMSZoning\"] = full.MSZoning.map({'C (all)':1, 'RH':2, 'RM':2, 'RL':3, 'FV':4})\n",
    "    \n",
    "    full[\"oNeighborhood\"] = full.Neighborhood.map({'MeadowV':1,\n",
    "                                               'IDOTRR':2, 'BrDale':2,\n",
    "                                               'OldTown':3, 'Edwards':3, 'BrkSide':3,\n",
    "                                               'Sawyer':4, 'Blueste':4, 'SWISU':4, 'NAmes':4,\n",
    "                                               'NPkVill':5, 'Mitchel':5,\n",
    "                                               'SawyerW':6, 'Gilbert':6, 'NWAmes':6,\n",
    "                                               'Blmngtn':7, 'CollgCr':7, 'ClearCr':7, 'Crawfor':7,\n",
    "                                               'Veenker':8, 'Somerst':8, 'Timber':8,\n",
    "                                               'StoneBr':9,\n",
    "                                               'NoRidge':10, 'NridgHt':10})\n",
    "    \n",
    "    full[\"oCondition1\"] = full.Condition1.map({'Artery':1,\n",
    "                                           'Feedr':2, 'RRAe':2,\n",
    "                                           'Norm':3, 'RRAn':3,\n",
    "                                           'PosN':4, 'RRNe':4,\n",
    "                                           'PosA':5 ,'RRNn':5})\n",
    "    \n",
    "    full[\"oBldgType\"] = full.BldgType.map({'2fmCon':1, 'Duplex':1, 'Twnhs':1, '1Fam':2, 'TwnhsE':2})\n",
    "    \n",
    "    full[\"oHouseStyle\"] = full.HouseStyle.map({'1.5Unf':1, \n",
    "                                           '1.5Fin':2, '2.5Unf':2, 'SFoyer':2, \n",
    "                                           '1Story':3, 'SLvl':3,\n",
    "                                           '2Story':4, '2.5Fin':4})\n",
    "    \n",
    "    full[\"oExterior1st\"] = full.Exterior1st.map({'BrkComm':1,\n",
    "                                             'AsphShn':2, 'CBlock':2, 'AsbShng':2,\n",
    "                                             'WdShing':3, 'Wd Sdng':3, 'MetalSd':3, 'Stucco':3, 'HdBoard':3,\n",
    "                                             'BrkFace':4, 'Plywood':4,\n",
    "                                             'VinylSd':5,\n",
    "                                             'CemntBd':6,\n",
    "                                             'Stone':7, 'ImStucc':7})\n",
    "    \n",
    "    full[\"oMasVnrType\"] = full.MasVnrType.map({'BrkCmn':1, 'None':1, 'BrkFace':2, 'Stone':3})\n",
    "    \n",
    "    full[\"oExterQual\"] = full.ExterQual.map({'Fa':1, 'TA':2, 'Gd':3, 'Ex':4})\n",
    "    \n",
    "    full[\"oFoundation\"] = full.Foundation.map({'Slab':1, \n",
    "                                           'BrkTil':2, 'CBlock':2, 'Stone':2,\n",
    "                                           'Wood':3, 'PConc':4})\n",
    "    \n",
    "    full[\"oBsmtQual\"] = full.BsmtQual.map({'Fa':2, 'None':1, 'TA':3, 'Gd':4, 'Ex':5})\n",
    "    \n",
    "    full[\"oBsmtExposure\"] = full.BsmtExposure.map({'None':1, 'No':2, 'Av':3, 'Mn':3, 'Gd':4})\n",
    "    \n",
    "    full[\"oHeating\"] = full.Heating.map({'Floor':1, 'Grav':1, 'Wall':2, 'OthW':3, 'GasW':4, 'GasA':5})\n",
    "    \n",
    "    full[\"oHeatingQC\"] = full.HeatingQC.map({'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5})\n",
    "    \n",
    "    full[\"oKitchenQual\"] = full.KitchenQual.map({'Fa':1, 'TA':2, 'Gd':3, 'Ex':4})\n",
    "    \n",
    "    full[\"oFunctional\"] = full.Functional.map({'Maj2':1, 'Maj1':2, 'Min1':2, 'Min2':2, 'Mod':2, 'Sev':2, 'Typ':3})\n",
    "    \n",
    "    full[\"oFireplaceQu\"] = full.FireplaceQu.map({'None':1, 'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5})\n",
    "    \n",
    "    full[\"oGarageType\"] = full.GarageType.map({'CarPort':1, 'None':1,\n",
    "                                           'Detchd':2,\n",
    "                                           '2Types':3, 'Basment':3,\n",
    "                                           'Attchd':4, 'BuiltIn':5})\n",
    "    \n",
    "    full[\"oGarageFinish\"] = full.GarageFinish.map({'None':1, 'Unf':2, 'RFn':3, 'Fin':4})\n",
    "    \n",
    "    full[\"oPavedDrive\"] = full.PavedDrive.map({'N':1, 'P':2, 'Y':3})\n",
    "    \n",
    "    full[\"oSaleType\"] = full.SaleType.map({'COD':1, 'ConLD':1, 'ConLI':1, 'ConLw':1, 'Oth':1, 'WD':1,\n",
    "                                       'CWD':2, 'Con':3, 'New':3})\n",
    "    \n",
    "    full[\"oSaleCondition\"] = full.SaleCondition.map({'AdjLand':1, 'Abnorml':2, 'Alloca':2, 'Family':2, 'Normal':3, 'Partial':4})            \n",
    "                \n",
    "                        \n",
    "                        \n",
    "    \n",
    "    return \"Done!\"\n",
    "map_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_uuid": "8ced8dac8d7dfd28ed10e45be2aab688f2e28b85"
   },
   "outputs": [],
   "source": [
    "# drop two unwanted columns\n",
    "full.drop(\"LotAreaCut\",axis=1,inplace=True)\n",
    "full.drop(['SalePrice'],axis=1,inplace=True)\n",
    "\n",
    "\n",
    "class labelenc(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self,X):\n",
    "        lab=LabelEncoder()\n",
    "        X[\"YearBuilt\"] = lab.fit_transform(X[\"YearBuilt\"])\n",
    "        X[\"YearRemodAdd\"] = lab.fit_transform(X[\"YearRemodAdd\"])\n",
    "        X[\"GarageYrBlt\"] = lab.fit_transform(X[\"GarageYrBlt\"])\n",
    "        return X\n",
    "class skew_dummies(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self,skew=0.5):\n",
    "        self.skew = skew\n",
    "    \n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self,X):\n",
    "        X_numeric=X.select_dtypes(exclude=[\"object\"])\n",
    "        skewness = X_numeric.apply(lambda x: skew(x))\n",
    "        skewness_features = skewness[abs(skewness) >= self.skew].index\n",
    "        X[skewness_features] = np.log1p(X[skewness_features])\n",
    "        X = pd.get_dummies(X)\n",
    "        return X\n",
    "# build pipeline\n",
    "pipe = Pipeline([\n",
    "    ('labenc', labelenc()),\n",
    "    ('skew_dummies', skew_dummies(skew=1)),\n",
    "    ])\n",
    "# save the original data for later use\n",
    "full2 = full.copy()\n",
    "data_pipe = pipe.fit_transform(full2)\n",
    "\n",
    "data_pipe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_uuid": "b89d7047c2f11491013623ed0e75b69eae1f1634",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "\n",
    "n_train=train.shape[0]\n",
    "\n",
    "X = data_pipe[:n_train]\n",
    "test_X = data_pipe[n_train:]\n",
    "y= train.SalePrice\n",
    "\n",
    "X_scaled = scaler.fit(X).transform(X)\n",
    "y_log = np.log(train.SalePrice)\n",
    "test_X_scaled = scaler.transform(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_uuid": "0b8735be158c8f9ec495425017ec0cf39d75fdb3"
   },
   "outputs": [],
   "source": [
    "lasso=Lasso(alpha=0.001)\n",
    "lasso.fit(X_scaled,y_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_uuid": "debca8e2920de67b70ec62e516db6714ff0b25bb"
   },
   "outputs": [],
   "source": [
    "FI_lasso = pd.DataFrame({\"Feature Importance\":lasso.coef_}, index=data_pipe.columns)\n",
    "\n",
    "FI_lasso.sort_values(\"Feature Importance\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_uuid": "6dc2b8106cf699bb4643268190625badb993f138"
   },
   "outputs": [],
   "source": [
    "FI_lasso[FI_lasso[\"Feature Importance\"]!=0].sort_values(\"Feature Importance\").plot(kind=\"barh\",figsize=(15,25))\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "_uuid": "d8e0e55c8ab9ca1735f1392f9925c7db296bd6b5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class add_feature(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self,additional=1):\n",
    "        self.additional = additional\n",
    "    \n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self,X):\n",
    "        if self.additional==1:\n",
    "            X[\"TotalHouse\"] = X[\"TotalBsmtSF\"] + X[\"1stFlrSF\"] + X[\"2ndFlrSF\"]   \n",
    "            X[\"TotalArea\"] = X[\"TotalBsmtSF\"] + X[\"1stFlrSF\"] + X[\"2ndFlrSF\"] + X[\"GarageArea\"]\n",
    "            \n",
    "        else:\n",
    "            X[\"TotalHouse\"] = X[\"TotalBsmtSF\"] + X[\"1stFlrSF\"] + X[\"2ndFlrSF\"]   \n",
    "            X[\"TotalArea\"] = X[\"TotalBsmtSF\"] + X[\"1stFlrSF\"] + X[\"2ndFlrSF\"] + X[\"GarageArea\"]\n",
    "            \n",
    "            X[\"+_TotalHouse_OverallQual\"] = X[\"TotalHouse\"] * X[\"OverallQual\"]\n",
    "            X[\"+_GrLivArea_OverallQual\"] = X[\"GrLivArea\"] * X[\"OverallQual\"]\n",
    "            X[\"+_oMSZoning_TotalHouse\"] = X[\"oMSZoning\"] * X[\"TotalHouse\"]\n",
    "            X[\"+_oMSZoning_OverallQual\"] = X[\"oMSZoning\"] + X[\"OverallQual\"]\n",
    "            X[\"+_oMSZoning_YearBuilt\"] = X[\"oMSZoning\"] + X[\"YearBuilt\"]\n",
    "            X[\"+_oNeighborhood_TotalHouse\"] = X[\"oNeighborhood\"] * X[\"TotalHouse\"]\n",
    "            X[\"+_oNeighborhood_OverallQual\"] = X[\"oNeighborhood\"] + X[\"OverallQual\"]\n",
    "            X[\"+_oNeighborhood_YearBuilt\"] = X[\"oNeighborhood\"] + X[\"YearBuilt\"]\n",
    "            X[\"+_BsmtFinSF1_OverallQual\"] = X[\"BsmtFinSF1\"] * X[\"OverallQual\"]\n",
    "            \n",
    "            X[\"-_oFunctional_TotalHouse\"] = X[\"oFunctional\"] * X[\"TotalHouse\"]\n",
    "            X[\"-_oFunctional_OverallQual\"] = X[\"oFunctional\"] + X[\"OverallQual\"]\n",
    "            X[\"-_LotArea_OverallQual\"] = X[\"LotArea\"] * X[\"OverallQual\"]\n",
    "            X[\"-_TotalHouse_LotArea\"] = X[\"TotalHouse\"] + X[\"LotArea\"]\n",
    "            X[\"-_oCondition1_TotalHouse\"] = X[\"oCondition1\"] * X[\"TotalHouse\"]\n",
    "            X[\"-_oCondition1_OverallQual\"] = X[\"oCondition1\"] + X[\"OverallQual\"]\n",
    "            \n",
    "           \n",
    "            X[\"Bsmt\"] = X[\"BsmtFinSF1\"] + X[\"BsmtFinSF2\"] + X[\"BsmtUnfSF\"]\n",
    "            X[\"Rooms\"] = X[\"FullBath\"]+X[\"TotRmsAbvGrd\"]\n",
    "            X[\"PorchArea\"] = X[\"OpenPorchSF\"]+X[\"EnclosedPorch\"]+X[\"3SsnPorch\"]+X[\"ScreenPorch\"]\n",
    "            X[\"TotalPlace\"] = X[\"TotalBsmtSF\"] + X[\"1stFlrSF\"] + X[\"2ndFlrSF\"] + X[\"GarageArea\"] + X[\"OpenPorchSF\"]+X[\"EnclosedPorch\"]+X[\"3SsnPorch\"]+X[\"ScreenPorch\"]\n",
    "\n",
    "    \n",
    "            return X\n",
    "\n",
    "   \n",
    "pipe = Pipeline([\n",
    "    ('labenc', labelenc()),\n",
    "    ('add_feature', add_feature(additional=2)),\n",
    "    ('skew_dummies', skew_dummies(skew=1)),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "_uuid": "b6446a6e3b1731e2d3fa39dbfaa9e245d5d335da"
   },
   "outputs": [],
   "source": [
    "full_pipe = pipe.fit_transform(full)\n",
    "\n",
    "full_pipe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "_uuid": "336018818ec98ec694d3280c8f85417c908032cd"
   },
   "outputs": [],
   "source": [
    "n_train=train.shape[0]\n",
    "X = full_pipe[:n_train]\n",
    "test_X = full_pipe[n_train:]\n",
    "y= train.SalePrice\n",
    "\n",
    "X_scaled = scaler.fit(X).transform(X)\n",
    "y_log = np.log(train.SalePrice)\n",
    "test_X_scaled = scaler.transform(test_X)\n",
    "\n",
    "pca = PCA(n_components=410)\n",
    "\n",
    "X_scaled=pca.fit_transform(X_scaled)\n",
    "test_X_scaled = pca.transform(test_X_scaled)\n",
    "\n",
    "X_scaled.shape, test_X_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "_uuid": "335d458533957932bab34b9d691197716119750b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define cross validation strategy\n",
    "def rmse_cv(model,X,y):\n",
    "    rmse = np.sqrt(-cross_val_score(model, X, y, scoring=\"neg_mean_squared_error\", cv=5))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "_uuid": "9ed55107ab82d23a2bc12caa1e35cf8ad0ad6722"
   },
   "outputs": [],
   "source": [
    "models = [LinearRegression(),Ridge(),Lasso(alpha=0.01,max_iter=10000),RandomForestRegressor(),GradientBoostingRegressor(),SVR(),LinearSVR(),\n",
    "          ElasticNet(alpha=0.001,max_iter=10000),SGDRegressor(max_iter=1000,tol=1e-3),BayesianRidge(),KernelRidge(alpha=0.6, kernel='polynomial', degree=2, coef0=2.5),\n",
    "          ExtraTreesRegressor(),XGBRegressor()]\n",
    "\n",
    "names = [\"LR\", \"Ridge\", \"Lasso\", \"RF\", \"GBR\", \"SVR\", \"LinSVR\", \"Ela\",\"SGD\",\"Bay\",\"Ker\",\"Extra\",\"Xgb\"]\n",
    "for name, model in zip(names, models):\n",
    "    score = rmse_cv(model, X_scaled, y_log)\n",
    "    print(\"{}: {:.6f}, {:.4f}\".format(name,score.mean(),score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "_uuid": "46fa2586a16862599024365eeb15a46c07d90918",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class grid():\n",
    "    def __init__(self,model):\n",
    "        self.model = model\n",
    "    \n",
    "    def grid_get(self,X,y,param_grid):\n",
    "        grid_search = GridSearchCV(self.model,param_grid,cv=5, scoring=\"neg_mean_squared_error\")\n",
    "        grid_search.fit(X,y)\n",
    "        print(grid_search.best_params_, np.sqrt(-grid_search.best_score_))\n",
    "        grid_search.cv_results_['mean_test_score'] = np.sqrt(-grid_search.cv_results_['mean_test_score'])\n",
    "        print(pd.DataFrame(grid_search.cv_results_)[['params','mean_test_score','std_test_score']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "_uuid": "cf86a05dbec6c67f9f16d6fb8208660d22ba78e3"
   },
   "outputs": [],
   "source": [
    "grid(Lasso()).grid_get(X_scaled,y_log,{'alpha': [0.0004,0.0005,0.0007,0.0009],'max_iter':[10000]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "_uuid": "399d61b9980e01e106925d1e0051e3d4d072e692"
   },
   "outputs": [],
   "source": [
    "grid(Ridge()).grid_get(X_scaled,y_log,{'alpha':[35,40,45,50,55,60,65,70,80,90]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "_uuid": "0393d0770fdf6001803c34f97bf17983084c298b"
   },
   "outputs": [],
   "source": [
    "grid(SVR()).grid_get(X_scaled,y_log,{'C':[11,13,15],'kernel':[\"rbf\"],\"gamma\":[0.0003,0.0004],\"epsilon\":[0.008,0.009]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "_uuid": "f2bdf5f8651239815243f4bab3f67e5a337bc600"
   },
   "outputs": [],
   "source": [
    "param_grid={'alpha':[0.2,0.3,0.4], 'kernel':[\"polynomial\"], 'degree':[3],'coef0':[0.8,1]}\n",
    "grid(KernelRidge()).grid_get(X_scaled,y_log,param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "_uuid": "e9ce5906138f45e19226a3e298807bf753c455a0"
   },
   "outputs": [],
   "source": [
    "grid(ElasticNet()).grid_get(X_scaled,y_log,{'alpha':[0.0008,0.004,0.005],'l1_ratio':[0.08,0.1,0.3],'max_iter':[10000]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "_uuid": "c1a6e19440cf3ddfc3aec53cae81b178fdaf5f8c"
   },
   "outputs": [],
   "source": [
    "class AverageWeight(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self,mod,weight):\n",
    "        self.mod = mod\n",
    "        self.weight = weight\n",
    "        \n",
    "    def fit(self,X,y):\n",
    "        self.models_ = [clone(x) for x in self.mod]\n",
    "        for model in self.models_:\n",
    "            model.fit(X,y)\n",
    "        return self\n",
    "    \n",
    "    def predict(self,X):\n",
    "        w = list()\n",
    "        pred = np.array([model.predict(X) for model in self.models_])\n",
    "        # for every data point, single model prediction times weight, then add them together\n",
    "        for data in range(pred.shape[1]):\n",
    "            single = [pred[model,data]*weight for model,weight in zip(range(pred.shape[0]),self.weight)]\n",
    "            w.append(np.sum(single))\n",
    "        return w\n",
    "\n",
    "lasso = Lasso(alpha=0.0005,max_iter=10000)\n",
    "ridge = Ridge(alpha=60)\n",
    "svr = SVR(gamma= 0.0004,kernel='rbf',C=13,epsilon=0.009)\n",
    "ker = KernelRidge(alpha=0.2 ,kernel='polynomial',degree=3 , coef0=0.8)\n",
    "ela = ElasticNet(alpha=0.005,l1_ratio=0.08,max_iter=10000)\n",
    "bay = BayesianRidge()\n",
    "\n",
    "# assign weights based on their gridsearch score\n",
    "w1 = 0.02\n",
    "w2 = 0.2\n",
    "w3 = 0.25\n",
    "w4 = 0.3\n",
    "w5 = 0.03\n",
    "w6 = 0.2\n",
    "\n",
    "weight_avg = AverageWeight(mod = [lasso,ridge,svr,ker,ela,bay],weight=[w1,w2,w3,w4,w5,w6])\n",
    "\n",
    "score = rmse_cv(weight_avg,X_scaled,y_log)\n",
    "print(score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "_uuid": "65bf87102cf8b219dc28ad97cdae708459aadcbf"
   },
   "outputs": [],
   "source": [
    "class stacking(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self,mod,meta_model):\n",
    "        self.mod = mod\n",
    "        self.meta_model = meta_model\n",
    "        self.kf = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "        \n",
    "    def fit(self,X,y):\n",
    "        self.saved_model = [list() for i in self.mod]\n",
    "        oof_train = np.zeros((X.shape[0], len(self.mod)))\n",
    "        \n",
    "        for i,model in enumerate(self.mod):\n",
    "            for train_index, val_index in self.kf.split(X,y):\n",
    "                renew_model = clone(model)\n",
    "                renew_model.fit(X[train_index], y[train_index])\n",
    "                self.saved_model[i].append(renew_model)\n",
    "                oof_train[val_index,i] = renew_model.predict(X[val_index])\n",
    "        \n",
    "        self.meta_model.fit(oof_train,y)\n",
    "        return self\n",
    "    \n",
    "    def predict(self,X):\n",
    "        whole_test = np.column_stack([np.column_stack(model.predict(X) for model in single_model).mean(axis=1) \n",
    "                                      for single_model in self.saved_model]) \n",
    "        return self.meta_model.predict(whole_test)\n",
    "    \n",
    "    def get_oof(self,X,y,test_X):\n",
    "        oof = np.zeros((X.shape[0],len(self.mod)))\n",
    "        test_single = np.zeros((test_X.shape[0],5))\n",
    "        test_mean = np.zeros((test_X.shape[0],len(self.mod)))\n",
    "        for i,model in enumerate(self.mod):\n",
    "            for j, (train_index,val_index) in enumerate(self.kf.split(X,y)):\n",
    "                clone_model = clone(model)\n",
    "                clone_model.fit(X[train_index],y[train_index])\n",
    "                oof[val_index,i] = clone_model.predict(X[val_index])\n",
    "                test_single[:,j] = clone_model.predict(test_X)\n",
    "            test_mean[:,i] = test_single.mean(axis=1)\n",
    "        return oof, test_mean\n",
    "# must do imputer first, otherwise stacking won't work, and i don't know why.\n",
    "a = Imputer().fit_transform(X_scaled)\n",
    "b = Imputer().fit_transform(y_log.values.reshape(-1,1)).ravel()\n",
    "\n",
    "stack_model = stacking(mod=[lasso,ridge,svr,ker,ela,bay],meta_model=ker)\n",
    "\n",
    "score = rmse_cv(stack_model,a,b)\n",
    "print(score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "_uuid": "1b16c5af2e1f65404e29bdc5c5635f5dc84e4cde"
   },
   "outputs": [],
   "source": [
    "# This is the final model I use\n",
    "stack_model = stacking(mod=[lasso,ridge,svr,ker,ela,bay],meta_model=ker)\n",
    "\n",
    "stack_model.fit(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "_uuid": "740a3dde75dd967fc102cc0638155d46e6a45b17",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = np.exp(stack_model.predict(test_X_scaled))\n",
    "\n",
    "result=pd.DataFrame({'Id':test.Id, 'SalePrice':pred})\n",
    "result.to_csv(\"submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "_uuid": "25cc51158d455f045aed8c7e19349dc9be8bbc65"
   },
   "outputs": [],
   "source": [
    "subm = pd.read_csv(\"submission.csv\")\n",
    "subm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1217f00296cb8b3b78ebf7bdcea01e9236d89369",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
